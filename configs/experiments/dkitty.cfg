[model]
input_dim = 56
time_dim = 256
condition_dim = 256
hidden_dim = 512
num_blocks = 6

[training]
num_timesteps = 1000
beta_start = 0.0001
beta_end = 0.02
alpha = 0.5
beta_w = 1.0
gamma = 10.0
batch_size = 64
learning_rate = 1e-4
num_epochs = 1000
optimizer = adamw
weight_decay = 0.01
scheduler = cosine
min_lr = 1e-6

[sampling]
num_samples = 256
guidance_scale = 10.0

[data]
task_name = dkitty
normalize = true 